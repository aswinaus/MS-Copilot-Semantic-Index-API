{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN/rHVUnOcdySva7Q00YY8R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswinaus/MS-Copilot-Semantic-Index-API/blob/main/Copilot_Retrieval_Reranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b710898"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace with your actual access token\n",
        "from google.colab import userdata\n",
        "GRAPH_TOKEN = userdata.get('GRAPH_TOKEN')\n",
        "access_token = GRAPH_TOKEN\n",
        "\n",
        "url = \"https://graph.microsoft.com/beta/copilot/retrieval\"\n",
        "\n",
        "headers = {\n",
        "  \"Authorization\": f\"Bearer {access_token}\",\n",
        "  \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "request_body = {\n",
        "  \"queryString\": \"Please get me information about how to request for access to EYI MyDocs workspace\",\n",
        "  \"dataSource\": \"sharePoint\",\n",
        "  \"resourceMetadata\": [\n",
        "    \"title\",\n",
        "    \"author\"\n",
        "  ],\n",
        "  \"maximumNumberOfResults\": \"10\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(request_body))\n",
        "\n",
        "if response.status_code == 200:\n",
        "  data = response.json()\n",
        "  print(\"API Call Successful:\")\n",
        "  print(json.dumps(data, indent=2))\n",
        "else:\n",
        "  print(f\"API Call Failed with status code: {response.status_code}\")\n",
        "  print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c006d5b"
      },
      "source": [
        "if response.status_code == 200:\n",
        "  data = response.json()\n",
        "  print(\"API Call Successful:\")\n",
        "\n",
        "  # Rerank the results based on relevance score\n",
        "  if \"retrievalHits\" in data:\n",
        "    reranked_hits = sorted(data[\"retrievalHits\"], key=lambda x: x.get(\"relevanceScore\", 0), reverse=True)\n",
        "    data[\"retrievalHits\"] = reranked_hits\n",
        "    print(\"Results reranked by relevance score.\")\n",
        "\n",
        "  print(json.dumps(data, indent=2))\n",
        "else:\n",
        "  print(f\"API Call Failed with status code: {response.status_code}\")\n",
        "  print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autoawq\n",
        "from awq import AutoAWQForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "from typing import Tuple, Optional, Union, Dict, Any\n",
        "from transformers import PreTrainedModel, AutoModel, AutoTokenizer, AutoConfig\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase"
      ],
      "metadata": {
        "id": "clOnT4ewAg5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive' # Input a data dir path from your mounted Google Drive\n",
        "quant_path = f\"/{data_dir}/LLMs/Mistral/Mistral-Small-24B-Instruct-2501\""
      ],
      "metadata": {
        "id": "6QoKERHxAlXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_model_path = quant_path\n",
        "local_tokenizer = AutoTokenizer.from_pretrained(quant_path)\n",
        "local_model = AutoModel.from_pretrained(quant_path,low_cpu_mem_usage=True)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "local_model.to(device)"
      ],
      "metadata": {
        "id": "LrYlAmJBApuC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}